[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "bifrost-eval"
version = "0.1.0"
description = "MCP pipeline evaluation toolkit â€” grade AI agent workflows on accuracy, cost, and reliability"
readme = "README.md"
license = "MIT"
requires-python = ">=3.11"
authors = [
    { name = "Jarrad Bermingham", email = "jarrad.bermingham@gmail.com" },
]
keywords = ["ai", "evaluation", "mcp", "agents", "testing", "llm"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Software Development :: Testing",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Typing :: Typed",
]
dependencies = [
    "pydantic>=2.0",
]

[project.optional-dependencies]
amf = ["agent-mcp-framework>=0.1.0"]
dev = [
    "pytest>=8.0",
    "pytest-asyncio>=0.24",
    "pytest-cov>=5.0",
    "hypothesis>=6.0",
    "ruff>=0.4",
    "pyright>=1.1",
    "bandit>=1.7",
    "pip-audit>=2.7",
]

[project.scripts]
bifrost-eval = "bifrost_eval.cli:main"

[project.urls]
Homepage = "https://github.com/Jbermingham1/bifrost-eval"
Repository = "https://github.com/Jbermingham1/bifrost-eval"
Issues = "https://github.com/Jbermingham1/bifrost-eval/issues"

[tool.hatch.build.targets.wheel]
packages = ["src/bifrost_eval"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
addopts = "--cov=bifrost_eval --cov-report=term-missing --cov-fail-under=80"

[tool.ruff]
target-version = "py311"
line-length = 100

[tool.ruff.lint]
select = ["E", "F", "W", "I", "N", "UP", "B", "A", "SIM", "TCH"]

[tool.pyright]
pythonVersion = "3.11"
typeCheckingMode = "strict"
include = ["src"]
